<!DOCTYPE HTML>
<html lang="en" class="sidebar-visible no-js light">

<head>
    <!-- Book generated using mdBook -->
    <meta charset="UTF-8">
    <title>Vollo Trees SDK User Guide</title>
    <meta name="robots" content="noindex" />


    <!-- Custom HTML head -->
    
    <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
    <meta name="description" content="">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="theme-color" content="#ffffff" />

    <link rel="shortcut icon" href="assets/vollo-favicon.png">
    <link rel="stylesheet" href="css/variables.css">
    <link rel="stylesheet" href="css/general.css">
    <link rel="stylesheet" href="css/chrome.css">
    <link rel="stylesheet" href="css/print.css" media="print">

    <!-- Fonts -->
    <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
    <link rel="stylesheet" href="fonts/fonts.css">

    <!-- Highlight.js Stylesheets -->
    <link rel="stylesheet" href="highlight.css">
    <link rel="stylesheet" href="tomorrow-night.css">
    <link rel="stylesheet" href="ayu-highlight.css">

    <!-- Custom theme stylesheets -->

</head>

<body>
    <!-- Provide site root to javascript -->
    <script type="text/javascript">
        var path_to_root = "";
        var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "light";
    </script>

    <!-- Work around some values being stored in localStorage wrapped in quotes -->
    <script type="text/javascript">
        try {
            var theme = localStorage.getItem('mdbook-theme');
            var sidebar = localStorage.getItem('mdbook-sidebar');

            if (theme.startsWith('"') && theme.endsWith('"')) {
                localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
            }

            if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
            }
        } catch (e) { }
    </script>

    <!-- Set the theme before any content is loaded, prevents flash -->
    <script type="text/javascript">
        var theme;
        try { theme = localStorage.getItem('mdbook-theme'); } catch (e) { }
        if (theme === null || theme === undefined) { theme = default_theme; }
        var html = document.querySelector('html');
        html.classList.remove('no-js')
        html.classList.remove('light')
        html.classList.add(theme);
        html.classList.add('js');
    </script>

    <!-- Hide / unhide sidebar before it is displayed -->
    <script type="text/javascript">
        var html = document.querySelector('html');
        var sidebar = 'hidden';
        if (document.body.clientWidth >= 1080) {
            try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch (e) { }
            sidebar = sidebar || 'visible';
        }
        html.classList.remove('sidebar-visible');
        html.classList.add("sidebar-" + sidebar);
    </script>

    <nav id="sidebar" class="sidebar" aria-label="Table of contents">
        <div class="sidebar-scrollbox">
            <a href="./">
                <h1 id="vollo-trees" class="sidebar-title"><a class="header" href="#vollo-trees">Vollo Trees</a></h1>
            </a>

            <ol class="chapter"><li class="chapter-item expanded affix "><a href="introduction.html">Introduction</a></li><li class="chapter-item expanded "><a href="installation.html"><strong aria-hidden="true">1.</strong> Installation</a></li><li class="chapter-item expanded "><a href="key-features.html"><strong aria-hidden="true">2.</strong> Key Features</a></li><li class="chapter-item expanded "><a href="getting-started.html"><strong aria-hidden="true">3.</strong> Getting Started</a></li><li class="chapter-item expanded "><a href="vollo-trees-compiler.html"><strong aria-hidden="true">4.</strong> Vollo Compiler</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="supported-models.html"><strong aria-hidden="true">4.1.</strong> Supported Models</a></li><li class="chapter-item expanded "><a href="example-compiler.html"><strong aria-hidden="true">4.2.</strong> Example</a></li></ol></li><li class="chapter-item expanded "><a href="benchmark.html"><strong aria-hidden="true">5.</strong> Benchmarks</a></li><li class="chapter-item expanded "><a href="accelerator-setup.html"><strong aria-hidden="true">6.</strong> Accelerator Setup</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="system-requirements.html"><strong aria-hidden="true">6.1.</strong> System Requirements</a></li><li class="chapter-item expanded "><a href="programming-the-fpga.html"><strong aria-hidden="true">6.2.</strong> Programming the FPGA</a></li><li class="chapter-item expanded "><a href="licensing.html"><strong aria-hidden="true">6.3.</strong> Licensing</a></li><li class="chapter-item expanded "><a href="running-an-example.html"><strong aria-hidden="true">6.4.</strong> Running an Example</a></li><li class="chapter-item expanded "><a href="running-the-benchmark.html"><strong aria-hidden="true">6.5.</strong> Running the Benchmark</a></li></ol></li><li class="chapter-item expanded "><a href="vollo-runtime.html"><strong aria-hidden="true">7.</strong> Vollo Runtime</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="c-api.html"><strong aria-hidden="true">7.1.</strong> C API</a></li><li class="chapter-item expanded "><a href="vollo-rt-example.html"><strong aria-hidden="true">7.2.</strong> C Example</a></li><li class="chapter-item expanded "><a href="vollo-rt-python-example.html"><strong aria-hidden="true">7.3.</strong> Python Example</a></li></ol></li><li class="chapter-item expanded "><a href="versions.html"><strong aria-hidden="true">8.</strong> Versions</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="release-notes.html"><strong aria-hidden="true">8.1.</strong> Release Notes</a></li></ol></li></ol>
        </div>
        <div id="sidebar-resize-handle" class="sidebar-resize-handle"></div>
    </nav>

    <div id="page-wrapper" class="page-wrapper">

        <div class="page">
                        <div id="menu-bar-hover-placeholder"></div>
            <div id="menu-bar" class="menu-bar sticky bordered">
                <div class="left-buttons">
                    <button id="sidebar-toggle" class="icon-button" type="button" title="Toggle Table of Contents"
                        aria-label="Toggle Table of Contents" aria-controls="sidebar">
                        <i class="fa fa-bars"></i>
                    </button>
                    <button id="theme-toggle" class="icon-button" type="button" title="Change theme"
                        aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                        <i class="fa fa-paint-brush"></i>
                    </button>
                    <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                        <li role="none"><button role="menuitem" class="theme" id="light">Light (default)</button></li>
                        <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                        <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                        <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                        <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button>
                        </li>
                    </ul>
                    <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)"
                        aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S"
                        aria-controls="searchbar">
                        <i class="fa fa-search"></i>
                    </button>
                </div>

                <h1 class="menu-title">Vollo Trees SDK User Guide</h1>

                <div class="right-buttons">
                    <a href="print.html" title="Print this book" aria-label="Print this book">
                        <i id="print-button" class="fa fa-print"></i>
                    </a>

                </div>
            </div>

            <div id="search-wrapper" class="hidden">
                <form id="searchbar-outer" class="searchbar-outer">
                    <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..."
                        aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                </form>
                <div id="searchresults-outer" class="searchresults-outer hidden">
                    <div id="searchresults-header" class="searchresults-header"></div>
                    <ul id="searchresults">
                    </ul>
                </div>
            </div>

            <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
            <script type="text/javascript">
                document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                Array.from(document.querySelectorAll('#sidebar a')).forEach(function (link) {
                    link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                });
            </script>

            <div id="content" class="content">
                <main>
                    <h1 id="introduction"><a class="header" href="#introduction">Introduction</a></h1>
<p>The <a href="https://github.com/MyrtleSoftware/vollo-trees-sdk">Vollo Trees SDK</a> is designed for
low latency streaming inference of decision tree models on FPGA
platforms.</p>
<blockquote>
<p>üîé See <a href="https://vollo.myrtle.ai/latest/">Vollo</a> for the parent product designed
for low latency streaming inference on Neural Networks.</p>
</blockquote>
<p>You can estimate the latency of your model using the Vollo Trees SDK without needing
an FPGA or a Vollo license, see <a href="getting-started.html">Getting Started</a> for
details.</p>
<p>This document outlines the following:</p>
<ul>
<li><a href="installation.html">Installation</a></li>
<li><a href="key-features.html">Key features of Vollo Trees</a></li>
<li><a href="getting-started.html">Steps to get started with Vollo Trees</a></li>
<li>The <a href="vollo-trees-compiler.html">Vollo Trees Compiler API</a></li>
<li>The <a href="vollo-runtime.html">Vollo Runtime API</a></li>
<li><a href="accelerator-setup.html">Hardware requirements and setup</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="installation"><a class="header" href="#installation">Installation</a></h1>
<p>The latest SDK is available for download from <a href="https://github.com/MyrtleSoftware/vollo-trees-sdk/releases">https://github.com/MyrtleSoftware/vollo-trees-sdk/releases</a>.</p>
<p>Download the <code>vollo-trees-sdk-&lt;version&gt;.run</code> self-extractable archive and execute it
to extract the Vollo Trees SDK contents to the current directory.</p>
<pre><code class="language-sh">chmod +x vollo-trees-sdk-&lt;version&gt;.run
./vollo-trees-sdk-&lt;version&gt;.run
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="key-features"><a class="header" href="#key-features">Key Features</a></h1>
<p>Vollo Trees accelerates machine learning inference for low latency streaming models
typically found in financial trading or fraud detection systems such as:</p>
<ul>
<li>Market predictions</li>
<li>Risk analysis</li>
<li>Anomaly detection</li>
<li>Portfolio optimisation</li>
</ul>
<p>Key characteristics of Vollo Trees are:</p>
<ul>
<li>Low latency inference decision tree models, typically between 1.9-2.4Œºs.</li>
<li>High density processing in a 1U server form factor suitable for co-located
server deployment.</li>
<li>Compiles decision tree models for use on the accelerator.</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="getting-started"><a class="header" href="#getting-started">Getting Started</a></h1>
<p>You can get started with evaluating your decision tree model's performance on Vollo Trees
using the Vollo Trees compiler which doesn't require an FPGA accelerator.</p>
<p>When you are ready, you can run inferences with your model on a Vollo FPGA
accelerator using an evaluation license.</p>
<h2 id="performance-estimation-and-model-design-with-the-vollo-trees-compiler"><a class="header" href="#performance-estimation-and-model-design-with-the-vollo-trees-compiler">Performance estimation and model design with the Vollo Trees compiler</a></h2>
<p>You can use the Vollo Trees compiler to compile and estimate the performance of
your model in an ML user's environment without any accelerator.</p>
<p><img src="assets/evaluation-flow-cpu-trees.svg" alt="CPU evaluation flow" /></p>
<p>The Vollo Trees compiler execution time is typically on the order of
seconds, enabling fast model iteration for tuning models to meet a latency
target.</p>
<p>To estimate performance of your model with the Vollo SDK:</p>
<ol>
<li>
<p><a href="installation.html">Download and extract</a> the Vollo SDK.</p>
</li>
<li>
<p><a href="vollo-trees-compiler.html#installation">Install the Vollo Trees compiler</a> Python libraries.</p>
</li>
<li>
<p>Compile your model using the Vollo-rtees compiler and evaluate the compiled program
on inference data to generate a compute latency estimate
that will be achieved with Vollo Trees.</p>
<p>See Vollo Trees compiler <a href="example-compiler.html">Example</a> for a fully worked example
of this including performance estimation.</p>
</li>
<li>
<p>Iterate on your model architecture to meet your combined latency and accuracy
requirements.</p>
</li>
</ol>
<h2 id="validating-inference-performance-using-the-vollo-trees-fpga-accelerator"><a class="header" href="#validating-inference-performance-using-the-vollo-trees-fpga-accelerator">Validating inference performance using the Vollo Trees FPGA accelerator</a></h2>
<p>When you are ready to run inferences with your models on a Vollo Trees accelerator,
you will need a <a href="system-requirements.html#accelerator-card-requirements">compatible FPGA based PCIe accelerator
card</a> and a <a href="licensing.html">Vollo Trees
license</a>.</p>
<p>Evaluation licenses can be provided free of charge by contacting
<a href="mailto:vollo@myrtle.ai">vollo@myrtle.ai</a>.</p>
<p><img src="assets/evaluation-flow-trees.svg" alt="FPGA evaluation flow" /></p>
<p>To validate inference performance on Vollo Trees:</p>
<!-- markdownlint-disable MD029 -->
<ol start="6">
<li>
<p>Follow the steps to <a href="programming-the-fpga.html">program</a> and
<a href="licensing.html">license</a> the FPGA.</p>
</li>
<li>
<p>Compile your model and save it as a <code>.vollo</code> program file using the Vollo Trees
compiler.</p>
<p>See Vollo Trees compiler <a href="example-compiler.html">Example</a> for a fully worked example.</p>
</li>
<li>
<p>Run and benchmark your model on the accelerator using <a href="running-an-example.html">the Vollo runtime C
example</a>.</p>
<p>Make sure to pass the example application the path to your saved <code>.vollo</code>
program when you invoke it on the command line.</p>
</li>
</ol>
<!-- markdownlint-enable MD029 -->
<p>Note that the Vollo Trees SDK includes prebuilt FPGA bitstreams for selected PCIe
accelerator cards so no FPGA compilation or configuration is required after
initial accelerator setup.
As a result loading user models to run on Vollo takes under a second, enabling
fast onboard iteration and evaluation of different models.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="vollo-compiler"><a class="header" href="#vollo-compiler">Vollo Compiler</a></h1>
<p>The <code>vollo-trees-compiler</code> Python library can compile an ONNX <code>TreeEnsembleRegressor</code> model
to a Vollo program (<code>.vollo</code> file). It also provides functionality to estimate the performance of
the Vollo program.</p>
<p>The <a href="vollo-runtime.html">Vollo Runtime</a> section describes how to run a Vollo
program on a Vollo accelerator.</p>
<h2 id="api-reference"><a class="header" href="#api-reference">API Reference</a></h2>
<p>This chapter walks through examples of how to use the Vollo compiler that
should cover the most commonly used parts of the API.</p>
<!-- markdown-link-check-disable -->
<p>A more complete API reference can be found <a href="./api-reference">here</a>.</p>
<!-- markdown-link-check-enable -->
<h2 id="installation-1"><a class="header" href="#installation-1">Installation</a></h2>
<p>Set up Vollo environment variables by <a href="accelerator-setup.html#environment-variable-setup">sourcing
<code>setup.sh</code></a> in <code>bash</code>.</p>
<p>Install the wheel file for the Vollo Trees compiler library. It's recommended that
you install this into a <a href="https://docs.python.org/3/library/venv.html">virtual
environment</a>.</p>
<p>Note: the packaged wheel only supports python 3.7 or greater</p>
<pre><code class="language-sh">python3 -m venv vollo-venv
source vollo-venv/bin/activate
pip install --upgrade pip
pip install "$VOLLO_SDK"/python/*.whl
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="supported-models"><a class="header" href="#supported-models">Supported Models</a></h1>
<p>The vollo-trees-compiler converts ONNX models containing a <a href="https://onnx.ai/onnx/operators/onnx_aionnxml_TreeEnsembleRegressor.html"><code>TreeEnsembleRegressor</code></a> node into Vollo programs.</p>
<p>The <a href="https://onnx.ai/sklearn-onnx/"><code>skl2onnx</code></a> and <a href="https://pypi.org/project/onnxmltools/1.0.0.0/"><code>onnxmltools</code></a> python libraries provide functionality for converting
decision tree regressors from various machine learning libraries into ONNX.</p>
<p>For example, to convert a scikit-learn <code>RandomForestRegressor</code> into a Vollo program:</p>
<pre><code class="language-python"><span class="boring">import numpy as np
</span>import vollo_trees_compiler as vtc
from sklearn.ensemble import RandomForestRegressor
from skl2onnx.common.data_types import FloatTensorType
from skl2onnx import convert_sklearn

n_estimators = 256
max_depth = 8
n_features = 256
<span class="boring">n_samples = 2**max_depth
</span><span class="boring">X = np.random.rand(n_samples, n_features)
</span><span class="boring">y = np.random.rand(n_samples)
</span>
random_forest = RandomForestRegressor(
    n_estimators=n_estimators, max_depth=max_depth
)

# Fit some given data X, y
random_forest.fit(X, y)

# Convert the model to ONNX
initial_type = [("input", FloatTensorType([1, n_features]))]
onnx_model = convert_sklearn(
    random_forest,
    initial_types=initial_type,
    target_opset=12
)

with open("sklearn_model.onnx", "wb") as f:
  f.write(onnx_model.SerializeToString())

config = vtc.Config.ia420f_u128()

forest = vtc.Forest.from_onnx("sklearn_model.onnx")
program = forest.to_program_bf16(config)
program.save("sklearn_model.vollo")
</code></pre>
<p>See <a href="https://onnx.ai/sklearn-onnx/tutorial_1-5_external.html">the sklearn-onnx documentation</a> for details on converting from <code>LightGBM</code>, <code>XGBoost</code> and <code>CatBoost</code> to ONNX.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="example"><a class="header" href="#example">Example</a></h1>
<p>The Vollo Trees compiler expects an ONNX model with a <code>TreeEnsembleRegressor</code> node as input.</p>
<pre><code class="language-python"><span class="boring">import numpy as np
</span>import vollo_trees_compiler as vtc
from sklearn.ensemble import RandomForestRegressor
from skl2onnx.common.data_types import FloatTensorType
from skl2onnx import convert_sklearn

n_estimators = 256
max_depth = 8
n_features = 256
<span class="boring">n_samples = 2**max_depth
</span><span class="boring">X = np.random.rand(n_samples, n_features)
</span><span class="boring">y = np.random.rand(n_samples)
</span>
random_forest = RandomForestRegressor(
    n_estimators=n_estimators, max_depth=max_depth
)

# Fit some given data X, y
random_forest.fit(X, y)

# Convert the model to ONNX
initial_type = [("input", FloatTensorType([n_features]))]
onnx_model = convert_sklearn(
    random_forest,
    initial_types=initial_type,
    target_opset=12
)

with open("sklearn_model.onnx", "wb") as f:
  f.write(onnx_model.SerializeToString())
</code></pre>
<p>The first stage of compiling a model is to lower it to a <code>vollo_trees_compiler.Forest</code>.
This is the Vollo Trees compiler's intermediate representation for representing decision tree ensembles.</p>
<pre><code class="language-python">import numpy as np
<span class="boring">import vollo_trees_compiler as vtc
</span><span class="boring">from sklearn.ensemble import RandomForestRegressor
</span><span class="boring">from skl2onnx.common.data_types import FloatTensorType
</span><span class="boring">from skl2onnx import convert_sklearn
</span>
<span class="boring">n_estimators = 256
</span><span class="boring">max_depth = 8
</span><span class="boring">n_features = 256
</span><span class="boring">n_samples = 2**max_depth
</span><span class="boring">X = np.random.rand(n_samples, n_features)
</span><span class="boring">y = np.random.rand(n_samples)
</span><span class="boring">
</span><span class="boring">random_forest = RandomForestRegressor(
</span><span class="boring">    n_estimators=n_estimators, max_depth=max_depth
</span><span class="boring">)
</span><span class="boring">
</span><span class="boring"># Fit some given data X, y
</span><span class="boring">random_forest.fit(X, y)
</span><span class="boring">
</span><span class="boring"># Convert the model to ONNX
</span><span class="boring">initial_type = [("input", FloatTensorType([1, n_features]))]
</span><span class="boring">onnx_model = convert_sklearn(
</span><span class="boring">    random_forest,
</span><span class="boring">    initial_types=initial_type,
</span><span class="boring">    target_opset=12
</span><span class="boring">)
</span><span class="boring">
</span><span class="boring">with open("example_model.onnx", "wb") as f:
</span><span class="boring">  f.write(onnx_model.SerializeToString())
</span><span class="boring">
</span><span class="boring">model_path = "example_model.onnx"
</span>import vollo_trees_compiler as vtc

forest = vtc.Forest.from_onnx(model_path)
</code></pre>
<p>The <code>Forest</code> can be compiled to a Vollo program given a <code>vollo_trees_compiler.Config</code> accelerator configuration.</p>
<pre><code class="language-python">config = vtc.Config.ia420f_u128()
program_bf16 = forest.to_program_bf16(config)
</code></pre>
<p>Save the program to a file so that it can be used for inference by the <a href="vollo-runtime.html">Vollo
runtime</a>.</p>
<pre><code class="language-python">program_bf16.save('example.vollo')
</code></pre>
<h2 id="simulation"><a class="header" href="#simulation">Simulation</a></h2>
<p>The Vollo Trees compiler can be used to evaluate a program on a given input which can be used to</p>
<ul>
<li>Estimate the performance of a model. Optionally, a cycle count can be returned with the evaluation output.</li>
<li>Verify the correctness of the compilation stages, including the effect of quantisation.</li>
</ul>
<p>A <code>vollo_trees_compiler.Forest</code> can instead be converted to a <code>f32</code> program. This way, the comparators and inputs will not
be quantized to <code>bf16</code>, which can be useful for testing against other inference measures (e.g. <code>onnxruntime</code>). Note however that the <code>f32</code> program cannot be used with the <a href="vollo-runtime.html">Vollo runtime</a>.</p>
<p>The program can then be evaluated on an input to determine the output value and estimate the cycle count.</p>
<pre><code class="language-python">program_f32 = forest.to_program_f32(config)
# Note that even though the ONNX model expects a multi-dimensional input,
# Program evaluation (and the vollo-runtime) expects a flattened input
input = np.random.rand(n_features)

out_value, est_cycle_count = program_f32.eval_with_cycle_estimate(input)

print(f"f32 Program output: {out_value}")
print(f"Estimated cycle count: {est_cycle_count}")
</code></pre>
<p>You can also obtain a pessimistic cycle estimate which assumes that the maximum depth branch is
taken in each tree.</p>
<pre><code class="language-python">pessimistic_estimate = program_f32.pessimistic_cycle_estimate()
print(f"Pessimistic cycle estimate: {pessimistic_estimate}")
</code></pre>
<p>This evaluation can also be performed on the <code>bf16</code> quantized version of the program.</p>
<p>Note there will be some discrepancy between the estimated cycle count and the true
cycle count.
Also note that this estimate does not model the latency of the communication between
the host and the Vollo accelerator. The <a href="benchmark.html"><code>single-decision-t1-d1-f32</code> benchmark</a> the
round-trip latency for the smallest possible program. This can be added to the cycle count estimate
(accounting for the FPGA clock rate of 400mhz) to give an estimate for the overall latency of the model.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="benchmarks"><a class="header" href="#benchmarks">Benchmarks</a></h1>
<p>This section provides benchmarks for the Vollo Trees accelerator for a variety decision tree models.</p>
<p>Performance figures are given for two configurations of the Vollo accelerator.
A 256-unit configuration which is provided for the IA-840F accelerator card
and a 128-unit configuration which is provided for the IA-420F accelerator card.
If you require a different configuration, please contact us at <a href="mailto:vollo@myrtle.ai">vollo@myrtle.ai</a>.</p>
<p>All these performance numbers can be measured using the <code>vollo-trees-sdk</code> with the correct accelerator card
by running the provided <a href="running-the-benchmark.html">benchmark script</a>.</p>
<h2 id="ia-840f-256-units"><a class="header" href="#ia-840f-256-units">IA-840F: 256 units</a></h2>
<h3 id="raw-buffer-api"><a class="header" href="#raw-buffer-api">Raw buffer API</a></h3>
<p>This is using buffers allocated with <code>vollo_rt_get_raw_buffer</code> which lets the runtime skip IO copy.</p>
<div class="table-wrapper"><table><thead><tr><th style="text-align: left">model</th><th style="text-align: right">num trees</th><th style="text-align: right">max depth</th><th style="text-align: right">input features</th><th style="text-align: left">fully populated</th><th style="text-align: right">mean latency (us)</th><th style="text-align: right">99th percentile latency (us)</th></tr></thead><tbody>
<tr><td style="text-align: left">single-decision-t1-d1-f32</td><td style="text-align: right">1</td><td style="text-align: right">1</td><td style="text-align: right">32</td><td style="text-align: left">No</td><td style="text-align: right">1.7</td><td style="text-align: right">1.9</td></tr>
<tr><td style="text-align: left">example-t1000-d5-f128</td><td style="text-align: right">1000</td><td style="text-align: right">5</td><td style="text-align: right">128</td><td style="text-align: left">No</td><td style="text-align: right">1.9</td><td style="text-align: right">2.0</td></tr>
<tr><td style="text-align: left">example-t1000-d5-f128-full</td><td style="text-align: right">1000</td><td style="text-align: right">5</td><td style="text-align: right">128</td><td style="text-align: left">Yes</td><td style="text-align: right">1.8</td><td style="text-align: right">2.0</td></tr>
<tr><td style="text-align: left">example-t1000-d8-f128</td><td style="text-align: right">1000</td><td style="text-align: right">8</td><td style="text-align: right">128</td><td style="text-align: left">No</td><td style="text-align: right">1.9</td><td style="text-align: right">2.1</td></tr>
<tr><td style="text-align: left">example-t1000-d8-f128-full</td><td style="text-align: right">1000</td><td style="text-align: right">8</td><td style="text-align: right">128</td><td style="text-align: left">Yes</td><td style="text-align: right">1.9</td><td style="text-align: right">2.1</td></tr>
<tr><td style="text-align: left">example-t512-d8-f512</td><td style="text-align: right">512</td><td style="text-align: right">8</td><td style="text-align: right">512</td><td style="text-align: left">No</td><td style="text-align: right">1.9</td><td style="text-align: right">2.1</td></tr>
<tr><td style="text-align: left">example-t1024-d8-f1024</td><td style="text-align: right">1024</td><td style="text-align: right">8</td><td style="text-align: right">1024</td><td style="text-align: left">No</td><td style="text-align: right">2.0</td><td style="text-align: right">2.2</td></tr>
<tr><td style="text-align: left">example-t4096-d8-f1024-full</td><td style="text-align: right">4096</td><td style="text-align: right">8</td><td style="text-align: right">1024</td><td style="text-align: left">Yes</td><td style="text-align: right">2.2</td><td style="text-align: right">2.3</td></tr>
</tbody></table>
</div>
<h3 id="user-buffers"><a class="header" href="#user-buffers">User buffers</a></h3>
<div class="table-wrapper"><table><thead><tr><th style="text-align: left">model</th><th style="text-align: right">numtrees</th><th style="text-align: right">max depth</th><th style="text-align: right">input features</th><th style="text-align: left">fully populated</th><th style="text-align: right">mean latency (us)</th><th style="text-align: right">99th percentile latency (us)</th></tr></thead><tbody>
<tr><td style="text-align: left">single-decision-t1-d1-f32</td><td style="text-align: right">1</td><td style="text-align: right">1</td><td style="text-align: right">32</td><td style="text-align: left">No</td><td style="text-align: right">1.8</td><td style="text-align: right">2.0</td></tr>
<tr><td style="text-align: left">example-t1000-d5-f128</td><td style="text-align: right">1000</td><td style="text-align: right">5</td><td style="text-align: right">128</td><td style="text-align: left">No</td><td style="text-align: right">1.9</td><td style="text-align: right">2.1</td></tr>
<tr><td style="text-align: left">example-t1000-d5-f128-full</td><td style="text-align: right">1000</td><td style="text-align: right">5</td><td style="text-align: right">128</td><td style="text-align: left">Yes</td><td style="text-align: right">1.9</td><td style="text-align: right">2.1</td></tr>
<tr><td style="text-align: left">example-t1000-d8-f128</td><td style="text-align: right">1000</td><td style="text-align: right">8</td><td style="text-align: right">128</td><td style="text-align: left">No</td><td style="text-align: right">2.0</td><td style="text-align: right">2.2</td></tr>
<tr><td style="text-align: left">example-t1000-d8-f128-full</td><td style="text-align: right">1000</td><td style="text-align: right">8</td><td style="text-align: right">128</td><td style="text-align: left">Yes</td><td style="text-align: right">2.0</td><td style="text-align: right">2.1</td></tr>
<tr><td style="text-align: left">example-t512-d8-f512</td><td style="text-align: right">512</td><td style="text-align: right">8</td><td style="text-align: right">512</td><td style="text-align: left">No</td><td style="text-align: right">2.1</td><td style="text-align: right">2.3</td></tr>
<tr><td style="text-align: left">example-t1024-d8-f1024</td><td style="text-align: right">1024</td><td style="text-align: right">8</td><td style="text-align: right">1024</td><td style="text-align: left">No</td><td style="text-align: right">2.3</td><td style="text-align: right">2.5</td></tr>
<tr><td style="text-align: left">example-t4096-d8-f1024-full</td><td style="text-align: right">4096</td><td style="text-align: right">8</td><td style="text-align: right">1024</td><td style="text-align: left">Yes</td><td style="text-align: right">2.5</td><td style="text-align: right">2.7</td></tr>
</tbody></table>
</div><!-- markdownlint-disable MD024 -->
<h2 id="ia-420f"><a class="header" href="#ia-420f">IA-420F</a></h2>
<h3 id="raw-buffer-api-1"><a class="header" href="#raw-buffer-api-1">Raw buffer API</a></h3>
<div class="table-wrapper"><table><thead><tr><th style="text-align: left">model</th><th style="text-align: right">num trees</th><th style="text-align: right">max depth</th><th style="text-align: right">input features</th><th style="text-align: left">fully populated</th><th style="text-align: right">mean latency (us)</th><th style="text-align: right">99th percentile latency (us)</th></tr></thead><tbody>
<tr><td style="text-align: left">single-decision-t1-d1-f32</td><td style="text-align: right">1</td><td style="text-align: right">1</td><td style="text-align: right">32</td><td style="text-align: left">No</td><td style="text-align: right">1.7</td><td style="text-align: right">1.9</td></tr>
<tr><td style="text-align: left">example-t1000-d5-f128</td><td style="text-align: right">1000</td><td style="text-align: right">5</td><td style="text-align: right">128</td><td style="text-align: left">No</td><td style="text-align: right">1.9</td><td style="text-align: right">2.1</td></tr>
<tr><td style="text-align: left">example-t1000-d5-f128-full</td><td style="text-align: right">1000</td><td style="text-align: right">5</td><td style="text-align: right">128</td><td style="text-align: left">Yes</td><td style="text-align: right">1.9</td><td style="text-align: right">2.1</td></tr>
<tr><td style="text-align: left">example-t1000-d8-f128</td><td style="text-align: right">1000</td><td style="text-align: right">8</td><td style="text-align: right">128</td><td style="text-align: left">No</td><td style="text-align: right">1.9</td><td style="text-align: right">2.1</td></tr>
<tr><td style="text-align: left">example-t1000-d8-f128-full</td><td style="text-align: right">1000</td><td style="text-align: right">8</td><td style="text-align: right">128</td><td style="text-align: left">Yes</td><td style="text-align: right">1.9</td><td style="text-align: right">2.1</td></tr>
<tr><td style="text-align: left">example-t512-d8-f512</td><td style="text-align: right">512</td><td style="text-align: right">8</td><td style="text-align: right">512</td><td style="text-align: left">No</td><td style="text-align: right">1.9</td><td style="text-align: right">2.1</td></tr>
<tr><td style="text-align: left">example-t1024-d8-f1024</td><td style="text-align: right">1024</td><td style="text-align: right">8</td><td style="text-align: right">1024</td><td style="text-align: left">No</td><td style="text-align: right">2.0</td><td style="text-align: right">2.2</td></tr>
<tr><td style="text-align: left">example-t4096-d8-f1024-full</td><td style="text-align: right">4096</td><td style="text-align: right">8</td><td style="text-align: right">1024</td><td style="text-align: left">Yes</td><td style="text-align: right">2.5</td><td style="text-align: right">2.6</td></tr>
</tbody></table>
</div>
<h3 id="user-buffers-1"><a class="header" href="#user-buffers-1">User buffers</a></h3>
<div class="table-wrapper"><table><thead><tr><th style="text-align: left">model</th><th style="text-align: right">numtrees</th><th style="text-align: right">max depth</th><th style="text-align: right">input features</th><th style="text-align: left">fully populated</th><th style="text-align: right">mean latency (us)</th><th style="text-align: right">99th percentile latency (us)</th></tr></thead><tbody>
<tr><td style="text-align: left">single-decision-t1-d1-f32</td><td style="text-align: right">1</td><td style="text-align: right">1</td><td style="text-align: right">32</td><td style="text-align: left">No</td><td style="text-align: right">1.8</td><td style="text-align: right">1.9</td></tr>
<tr><td style="text-align: left">example-t1000-d5-f128</td><td style="text-align: right">1000</td><td style="text-align: right">5</td><td style="text-align: right">128</td><td style="text-align: left">No</td><td style="text-align: right">2.0</td><td style="text-align: right">2.2</td></tr>
<tr><td style="text-align: left">example-t1000-d5-f128-full</td><td style="text-align: right">1000</td><td style="text-align: right">5</td><td style="text-align: right">128</td><td style="text-align: left">Yes</td><td style="text-align: right">2.0</td><td style="text-align: right">2.1</td></tr>
<tr><td style="text-align: left">example-t1000-d8-f128</td><td style="text-align: right">1000</td><td style="text-align: right">8</td><td style="text-align: right">128</td><td style="text-align: left">No</td><td style="text-align: right">2.1</td><td style="text-align: right">2.2</td></tr>
<tr><td style="text-align: left">example-t1000-d8-f128-full</td><td style="text-align: right">1000</td><td style="text-align: right">8</td><td style="text-align: right">128</td><td style="text-align: left">Yes</td><td style="text-align: right">2.0</td><td style="text-align: right">2.2</td></tr>
<tr><td style="text-align: left">example-t512-d8-f512</td><td style="text-align: right">512</td><td style="text-align: right">8</td><td style="text-align: right">512</td><td style="text-align: left">No</td><td style="text-align: right">2.1</td><td style="text-align: right">2.3</td></tr>
<tr><td style="text-align: left">example-t1024-d8-f1024</td><td style="text-align: right">1024</td><td style="text-align: right">8</td><td style="text-align: right">1024</td><td style="text-align: left">No</td><td style="text-align: right">2.3</td><td style="text-align: right">2.5</td></tr>
<tr><td style="text-align: left">example-t4096-d8-f1024-full</td><td style="text-align: right">4096</td><td style="text-align: right">8</td><td style="text-align: right">1024</td><td style="text-align: left">Yes</td><td style="text-align: right">2.8</td><td style="text-align: right">3.0</td></tr>
</tbody></table>
</div><!-- markdownlint-enable MD024 --><div style="break-before: page; page-break-before: always;"></div><h1 id="setting-up-the-vollo-accelerator"><a class="header" href="#setting-up-the-vollo-accelerator">Setting up the Vollo accelerator</a></h1>
<p>This section describes how to program your accelerator card with the Vollo
Accelerator upon first use and how to reprogram your accelerator card with
updated versions of the Vollo Accelerator.
It also describes how to obtain a Vollo license which you will need to use the
Vollo accelerator.</p>
<h2 id="environment-variable-setup"><a class="header" href="#environment-variable-setup">Environment Variable Setup</a></h2>
<p>The initial setup instructions should be run in the Vollo SDK directory.</p>
<pre><code class="language-bash">cd vollo-trees-sdk-&lt;VERSION&gt;
</code></pre>
<p>When using Vollo, you should also have the <code>setup.sh</code> script sourced in <code>bash</code>
to set up environment variables used by Vollo:</p>
<pre><code class="language-bash">source setup.sh
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="system-requirements"><a class="header" href="#system-requirements">System Requirements</a></h1>
<h2 id="cpu-requirements"><a class="header" href="#cpu-requirements">CPU Requirements</a></h2>
<p>The minimum CPU specification for the system is shown below.</p>
<ul>
<li>Single Socket 6 core Intel Xeon CPU at 2.0 GHz, equivalent AMD processor or better.</li>
<li>8 GB RAM</li>
</ul>
<h2 id="accelerator-card-requirements"><a class="header" href="#accelerator-card-requirements">Accelerator Card Requirements</a></h2>
<p>The SDK runs on a server CPU with PCIe FPGA accelerator cards.
It currently supports the following accelerator cards:</p>
<div class="table-wrapper"><table><thead><tr><th>Accelerator Card</th><th>FPGA</th></tr></thead><tbody>
<tr><td>BittWare IA-420f</td><td>Intel Agilex AGF014</td></tr>
<tr><td>BittWare IA-840f</td><td>Intel Agilex AGF027</td></tr>
</tbody></table>
</div>
<h2 id="operating-system-requirements"><a class="header" href="#operating-system-requirements">Operating System Requirements</a></h2>
<p>Vollo is compatible with Ubuntu 20.04 and later.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="programming-the-fpga"><a class="header" href="#programming-the-fpga">Programming the FPGA</a></h1>
<h2 id="programming-the-fpga-via-jtag"><a class="header" href="#programming-the-fpga-via-jtag">Programming the FPGA via JTAG</a></h2>
<p>If your FPGA is not already programmed with the Vollo accelerator or the Vollo Trees accelerator then please
follow these instructions to load the bitstream into the accelerator card's
flash memory.</p>
<p>This requires a USB cable to be connected to the accelerator card and Quartus
programmer to be installed on the system so that the device can be programmed
over JTAG.</p>
<p>If the FPGA card already has a Vollo Accelerator Bitstream or a Vollo Trees accelerator bitstream, it can be updated
over PCIe by following the steps in the section <a href="programming-the-fpga.html#programming-the-fpga-via-pcie">Program the FPGA via
PCIe</a> below.
Note that you only need to update the bitstream if updating to an <a href="versions.html#version-compatibility">incompatible
version</a> of the Vollo SDK.
Programming over PCIe is faster than programming over JTAG, and does not
require a USB programming cable or for Quartus Programmer to be installed.</p>
<ol>
<li>
<p>Download and install the latest Quartus Programmer:</p>
<ul>
<li>Navigate to
<a href="https://www.intel.com/content/www/us/en/software-kit/782411/intel-quartus-prime-pro-edition-design-software-version-23-2-for-linux.html">https://www.intel.com/content/www/us/en/software-kit/782411/intel-quartus-prime-pro-edition-design-software-version-23-2-for-linux.html</a>.</li>
<li>Select <code>Additional Software</code> and scroll down to find the Programmer.</li>
<li>Follow the instructions for installation.</li>
</ul>
</li>
<li>
<p>Add Quartus programmer to your path:</p>
<pre><code class="language-sh">export QUARTUS_DIR=&lt;path to qprogrammer install&gt;
export PATH=$QUARTUS_DIR/qprogrammer/quartus/bin:$PATH
</code></pre>
</li>
<li>
<p>Start the jtag daemon:</p>
<pre><code class="language-sh">sudo killall jtagd
sudo jtagd
</code></pre>
</li>
<li>
<p>Run <code>jtagconfig</code> from the Quartus install, you should see the device(s):</p>
<pre><code class="language-sh">$ jtagconfig
1) IA-840F [1-5.2]
  0341B0DD   AGFB027R25A(.|R0)
</code></pre>
</li>
<li>
<p>Navigate to the directory containing the <code>jic</code> file:</p>
<pre><code class="language-sh">cd &lt;vollo-sdk&gt;/bitstream
</code></pre>
</li>
<li>
<p>Set the JTAG clock frequency of the device you want to program to 16 MHz.
Specify the device by providing the name returned by <code>jtagconfig</code>:</p>
<pre><code class="language-sh">jtagconfig --setparam "IA-840F [1-5.2]" JtagClock 16M
</code></pre>
</li>
<li>
<p>Start the programming operation on the chosen device. This takes around 20
minutes. For the IA840F:</p>
<pre><code class="language-sh">quartus_pgm -c "IA-840F [1-5.2]" -m JTAG -o "ipv;vollo-ia840f-u256d8192.jic"
</code></pre>
<p>Or for IA420F:</p>
<pre><code class="language-sh">quartus_pgm -c "IA-420F [1-5.2]" -m JTAG -o "ipv;vollo-ia420f-u128d8192.jic"
</code></pre>
</li>
<li>
<p>Go back to 6 and program any other devices.</p>
</li>
<li>
<p>Power off the system and start it back up. The bitstream will now be loaded
onto the FPGA.</p>
<blockquote>
<p>‚ö†Ô∏è For the configuration process to be triggered the board has to register
the power being off. It is recommended to turn the power off and then wait
a few seconds before turning the power back on to ensure this happens.</p>
</blockquote>
</li>
<li>
<p>Check a Vollo bitstream is loaded:</p>
<pre><code class="language-sh">$ lspci -d 1ed9:766f
51:00.0 Processing accelerators: Myrtle.ai Device 766f (rev 01)
</code></pre>
<p>Check the correct Vollo bitstream is loaded:</p>
<pre><code class="language-sh">cd &lt;vollo-sdk&gt;
bin/vollo-tool bitstream-check bitstream/&lt;bitstream-name&gt;.json
</code></pre>
</li>
</ol>
<h2 id="programming-the-fpga-via-pcie"><a class="header" href="#programming-the-fpga-via-pcie">Programming the FPGA via PCIe</a></h2>
<p>NOTE: this can only be done with an FPGA that is already programmed with a Vollo bitstream.</p>
<ol>
<li>
<p>Load the kernel driver:</p>
<pre><code class="language-sh">sudo ./load-kernel-driver.sh
</code></pre>
</li>
<li>
<p>Check the current bitstream information:</p>
<pre><code class="language-sh">bin/vollo-tool bitstream-info
</code></pre>
</li>
<li>
<p>Check that the device is set up for remote system updates by running the
command below, with <code>device index</code> representing the index of the device you
want to update, in the order shown in the previous command, starting from 0.
It should print a <code>json</code> string to the terminal showing the device status.</p>
<pre><code class="language-sh">bin/vollo-tool fpga-config rsu-status &lt;device index&gt;
</code></pre>
</li>
<li>
<p>Update the <code>USER_IMAGE</code> partition of the flash with the new bitstream image
contained in the <code>rpd</code> archive. This should take around 5 minutes. Do not
interrupt this process until it completes.</p>
<pre><code class="language-sh">sudo ./load-kernel-driver.sh
bin/vollo-tool fpga-config overwrite-partition &lt;device index&gt; &lt;.rpd.tar.gz file&gt; USER_IMAGE
</code></pre>
</li>
<li>
<p>Repeat step 4 for any other devices you wish to update.</p>
</li>
<li>
<p>Power off the system and start it back up.</p>
<blockquote>
<p>‚ö†Ô∏è For the configuration process to be triggered the board has to register
the power being off. It is recommended to turn the power off and then wait
a few seconds before turning the power back on to ensure this happens.</p>
</blockquote>
</li>
<li>
<p>Repeat steps 1, 2 and 3. The <code>bitstream-info</code> command should show that the
updated bitstream has been loaded (e.g. a newer release date), and the output
of the <code>rsu-status</code> command should show all zeroes for the <code>error_code</code> and
<code>failing_image_address</code> fields.</p>
</li>
<li>
<p>Check the correct Vollo bitstream is loaded:</p>
<pre><code class="language-sh">sudo ./load-kernel-driver.sh
bin/vollo-tool bitstream-check bitstream/&lt;bitstream-name&gt;.json
</code></pre>
</li>
</ol>
<div style="break-before: page; page-break-before: always;"></div><h1 id="licensing"><a class="header" href="#licensing">Licensing</a></h1>
<p>Vollo is licensed on a per-device basis.</p>
<h2 id="redeeming-licenses-with-vollo-tool"><a class="header" href="#redeeming-licenses-with-vollo-tool">Redeeming licenses with vollo-tool</a></h2>
<p>You will receive a <code>purchase-token</code> with your Vollo purchase. The <code>purchase-token</code> can be used to redeem Vollo licenses for a set number of devices.</p>
<p>To see the number of credits (i.e. the number of devices which can be redeemed) on your <code>purchase-token</code>, run:</p>
<pre><code class="language-sh">bin/vollo-tool license num-remaining-devices -t &lt;purchase-token&gt;
</code></pre>
<p>To redeem devices on your purchase token:</p>
<ol>
<li>
<p>Load the kernel driver if you haven't already done so:</p>
<pre><code class="language-sh">sudo ./load-kernel-driver.sh
</code></pre>
</li>
<li>
<p>Run <code>vollo-tool device-ids</code>. This will enumerate all Vollo accelerators and output their device IDs.</p>
<pre><code class="language-sh">bin/vollo-tool device-ids | tee vollo.devices
</code></pre>
</li>
<li>
<p>Run <code>vollo-tool license redeem-device</code>, passing the device IDs you wish to generate licenses for. This will print a breakdown of which devices will consume credits on the <code>purchase-token</code>.</p>
<pre><code class="language-sh">bin/vollo-tool license redeem-device -t &lt;purchase-token&gt; --device-ids &lt;device IDs&gt;
</code></pre>
<p>Alternatively you can pass the <code>vollo.devices</code> output from the previous step if you wish to redeem licenses for all devices.</p>
<pre><code class="language-sh">bin/vollo-tool license redeem-device -t &lt;purchase-token&gt; --device-id-file &lt;device ID file&gt;
</code></pre>
</li>
<li>
<p>When you have confirmed which devices will consume credits on the <code>purchase-token</code>, run <code>vollo-tool license redeem-device --consume-credits</code> to generate the licenses.
The licenses will be printed to <code>stdout</code>.</p>
<pre><code class="language-sh">bin/vollo-tool license redeem-device -t &lt;purchase-token&gt; --device-ids &lt;device IDs&gt; --consume-credits | tee vollo.lic
</code></pre>
</li>
</ol>
<p>The licenses redeemed on a purchase token can be viewed at any time by running <code>vollo-tool license view-licenses</code>:</p>
<pre><code class="language-sh">bin/vollo-tool license view-licenses -t &lt;purchase-token&gt; | tee vollo.lic
</code></pre>
<h2 id="installing-a-license"><a class="header" href="#installing-a-license">Installing a license</a></h2>
<ol>
<li>
<p>The license file location should be set in the environment variable <code>MYRTLE_LICENSE</code>.</p>
<pre><code class="language-sh">export MYRTLE_LICENSE=&lt;license file&gt;
</code></pre>
</li>
<li>
<p>Check that the license for your device(s) is being recognised.</p>
<pre><code class="language-sh">bin/vollo-tool license-check
</code></pre>
<p>If successful, the output should look like this:</p>
<pre><code class="language-output">Ok: found 2 devices with valid licenses
</code></pre>
</li>
</ol>
<div style="break-before: page; page-break-before: always;"></div><h1 id="running-an-example"><a class="header" href="#running-an-example">Running an example</a></h1>
<p>The Vollo Trees SDK contains a trivial program for each accelerator to check if the accelerator is working.</p>
<ol>
<li>
<p>Ensure you have run the setup steps:</p>
<pre><code class="language-sh">cd &lt;vollo-sdk&gt;
sudo ./load_kernel_driver.sh
source setup.sh
export MYRTLE_LICENSE=&lt;your-license-file&gt;
</code></pre>
</li>
<li>
<p>Compile the C runtime example:</p>
<pre><code class="language-sh">(cd example; make)
</code></pre>
</li>
<li>
<p>Run the example.</p>
<p>For a block-size 64 accelerator such as <code>vollo-ia840f-u256.jic</code>:</p>
<pre><code class="language-sh">./example/vollo-example example/single-decision-u256.vollo
</code></pre>
<p>For a block-size 32 accelerator such as <code>vollo-ia420f-u128d8192.jic</code>:</p>
<pre><code class="language-sh">./example/vollo-example example/single-decision-u128.vollo
</code></pre>
<p>You should see an output similar to the following:</p>
<pre><code class="language-sh">Using program: "example/single-decision-u256.vollo"
Using vollo-rt version: 20.0.0
Using Vollo accelerator with 256 tree unit(s)
Program metadata for model 0:
   1 input with shape: [32]
   1 output with shape: [1]
Starting 10000 inferences
Ran 10000 inferences in 0.018070 s with:
   mean latency of 1.790225 us
   99% latency of 1.942000 us
   throughput of 553402.910468 inf/s
Done
</code></pre>
</li>
</ol>
<div style="break-before: page; page-break-before: always;"></div><h1 id="running-the-benchmark"><a class="header" href="#running-the-benchmark">Running the benchmark</a></h1>
<p>The release comes with a benchmark script that can be used to measure the
performance of the accelerator for a variety of models.
The script uses the Vollo Trees compiler to compile the models for your accelerator and then runs the
models on the accelerator to measure the performance.</p>
<ol>
<li>
<p>Install the script dependencies:</p>
<pre><code class="language-bash">sudo apt install python3-venv jq
</code></pre>
<p>Note, the compiler requires python 3.7 or later.</p>
</li>
<li>
<p>Ensure you have run the setup steps:</p>
<pre><code class="language-sh">cd &lt;vollo-trees-sdk&gt;
sudo ./load_kernel_driver.sh
source setup.sh
export MYRTLE_LICENSE=&lt;your-license-file&gt;
</code></pre>
</li>
<li>
<p>Run the benchmark:</p>
<pre><code class="language-sh">$VOLLO_TREES_SDK/example/benchmark.sh
</code></pre>
</li>
<li>
<p>You can cross reference your numbers with those in the <a href="benchmark.html">benchmarks</a> section of the documentation.</p>
</li>
</ol>
<div style="break-before: page; page-break-before: always;"></div><h1 id="vollo-runtime"><a class="header" href="#vollo-runtime">Vollo Runtime</a></h1>
<p>The Vollo runtime provides a low latency asynchronous inference API for timing
critical inference requests on the Vollo accelerator.</p>
<p>A couple of example C programs that use the Vollo runtime API have been included in the
installation in the <code>example/</code> directory.</p>
<p>In order to use the Vollo runtime you need to have <a href="./accelerator-setup.html">an accelerator set up</a>:</p>
<ul>
<li><a href="./programming-the-fpga.html">A programmed FPGA</a></li>
<li><a href="./licensing.html">A loaded kernel driver and an installed license</a></li>
<li>Environment set up with <code>source setup.sh</code></li>
</ul>
<h2 id="python-api"><a class="header" href="#python-api">Python API</a></h2>
<p>The Vollo SDK includes Python bindings for the Vollo runtime. These can be more
convenient than the C API for e.g. testing Vollo against PyTorch models.</p>
<!-- markdown-link-check-disable -->
<p>The API for the Python bindings can be found <a href="./api-reference/vollo_rt.html">here</a>.</p>
<!-- markdown-link-check-enable -->
<p>A small example of using the Python bindings is provided <a href="./vollo-rt-python-example.html">here</a>.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="c-api"><a class="header" href="#c-api">C API</a></h1>
<p>The Vollo runtime API is a C API with simple types and functions in order to be
straight forward to use from any language with a C FFI.</p>
<ul>
<li>Header file: <code>$VOLLO_SDK/include/vollo-rt.h</code></li>
<li>Dynamic library: <code>$VOLLO_SDK/lib/libvollo_rt.so</code></li>
<li>Static library: <code>$VOLLO_SDK/lib/libvollo_rt.a</code></li>
</ul>
<p>It links against GLIBC (from version 2.27), contact us if you have other requirements.</p>
<p>To compile against Vollo RT with a standard C compiler, you can use the following flags:
<code>-I $VOLLO_SDK/include -L $VOLLO_SDK/lib -lvollo_rt</code></p>
<p>These are the main steps (in order) a program using <code>vollo_rt</code> will follow:</p>
<ol>
<li>Initialise the Vollo runtime using <code>vollo_rt_init</code></li>
<li>Add Vollo accelerators to the runtime using <code>vollo_rt_add_accelerator</code>
(Note: the current release only supports one accelerator)</li>
<li>Load a Vollo program onto the Vollo accelerators with <code>vollo_rt_load_program</code></li>
<li>Optionally, inspect the metadata about the models in the program using API calls such as
<code>vollo_rt_num_models</code> and <code>vollo_rt_model_num_inputs</code></li>
<li>Queue and run inference jobs by first calling <code>vollo_rt_add_job_bf16</code> (or
<code>vollo_rt_add_job_fp32</code>) and then polling in a loop for their completion using <code>vollo_rt_poll</code>.
You can queue several jobs before calling <code>vollo_rt_poll</code> or add extra jobs at any point.</li>
<li>Finally call <code>vollo_rt_destroy</code> to release resources.</li>
</ol>
<p>The API is designed to explicitly return errors when it can to let the user handle them as they see fit.
The metadata functions will instead error out themselves if any of the documented pre-conditions they rely on aren't met.
Any other crash is considered a bug and we would be very grateful if you could tell us about it.</p>
<h2 id="initialisation"><a class="header" href="#initialisation">Initialisation</a></h2>
<p>A vollo context is created by calling <code>vollo_rt_init</code>.
Add an accelerator by using the <code>vollo_rt_add_accelerator</code> function.</p>
<pre><code class="language-c">/**
 * Initialise the vollo-rt context. This must be called before any other vollo-rt functions.
 *
 * Logging level can be configured by setting the environment variable `VOLLO_RT_LOG` to one of:
 * "error", "warn", "info", "debug", or "trace"
 */
vollo_rt_error_t vollo_rt_init(vollo_rt_context_t* context_ptr);

/**
 * Destroy vollo-rt context, releasing its associated resources.
 */
void vollo_rt_destroy(vollo_rt_context_t vollo);

/**
 * Add an accelerator.
 * The accelerator is specified by its index. The index refers to an accelerator in the sorted list
 * of PCI addresses. This should be called after `vollo_rt_init` but before `vollo_rt_load_program`
 */
vollo_rt_error_t vollo_rt_add_accelerator(vollo_rt_context_t vollo, size_t accelerator_index);
</code></pre>
<h2 id="loading-a-program"><a class="header" href="#loading-a-program">Loading a program</a></h2>
<p>A program is loaded onto the Vollo accelerator using the <code>vollo_rt_load_program</code> function.</p>
<pre><code class="language-c">/**
 * Load a program onto the Vollo accelerators.
 * This should be called after `vollo_rt_add_accelerator`
 *
 * A Vollo program is generated by the Vollo compiler, it is typically named
 * "&lt;program_name&gt;.vollo".
 * The program is intended for a specific hardware config (number of accelerators,
 * cores and other configuration options), this function will return an
 * error if any accelerator configuration is incompatible with the program.
 * Once loaded, the program provides inference for several models concurrently.
 *
 * Note: This should only be called once per `vollo_rt_context_t`, as such if
 * a program needs to be changed or reset, first `vollo_rt_destroy` the current
 * context, then start a new context with `vollo_rt_init`.
 */
vollo_rt_error_t vollo_rt_load_program(vollo_rt_context_t vollo, const char* program_path);
</code></pre>
<h2 id="model-metadata"><a class="header" href="#model-metadata">Model metadata</a></h2>
<p>Once a program is loaded, it provides inference for one or more models. Metadata about
a model is obtained with <code>vollo_rt_model_*</code> functions.</p>
<p>Each model can have multiple distinct inputs and outputs. Each input and each output has
a multi-dimensional shape associated with it. All of the metadata is defined by the program
as supplied by the Vollo compiler. All the shapes are statically defined.</p>
<p>Some models can be compiled as streaming statefully over a dimension, that dimension is then
erased from the inference shape but its possition can be recovered in the model metadata.</p>
<pre><code class="language-c">/**
 * Inspect the number of models in the program loaded onto the vollo.
 *
 * Programs can contain multiple models, a `model_index` is used to select a
 * specific model
 */
size_t vollo_rt_num_models(vollo_rt_context_t vollo);

/**
 * Get the number of inputs of a model
 *
 * Each input has its own distinct shape
 *
 * Requirements (panics otherwise):
 * - a program was loaded with `vollo_rt_load_program`
 * - `model_index &lt; vollo_rt_num_models`
 */
size_t vollo_rt_model_num_inputs(vollo_rt_context_t vollo, size_t model_index);

/**
 * Get the number of outputs of a model
 *
 * Each output has its own distinct shape
 *
 * Requirements (panics otherwise):
 * - a program was loaded with `vollo_rt_load_program`
 * - `model_index &lt; vollo_rt_num_models`
 */
size_t vollo_rt_model_num_outputs(vollo_rt_context_t vollo, size_t model_index);

/**
 * Get the shape for input at a given index
 *
 * The return value is a 0 terminated array of dims containing the input shape
 * The value lives for as long as the model
 *
 * Requirements (panics otherwise):
 * - a program was loaded with `vollo_rt_load_program`
 * - `model_index &lt; vollo_rt_num_models`
 * - `input_index &lt; vollo_rt_model_num_inputs`
 */
const size_t* vollo_rt_model_input_shape(
  vollo_rt_context_t vollo, size_t model_index, size_t input_index);

/**
 * Get the shape for output at a given index
 *
 * The return value is a 0 terminated array of dims containing the output shape
 * The value lives for as long as the model
 *
 * Requirements (panics otherwise):
 * - a program was loaded with `vollo_rt_load_program`
 * - `model_index &lt; vollo_rt_num_models`
 * - `output_index &lt; vollo_rt_model_num_outputs`
 */
const size_t* vollo_rt_model_output_shape(
  vollo_rt_context_t vollo, size_t model_index, size_t output_index);

/**
 * Get the number of elements for input at a given index
 *
 * This is simply the product of the dimensions returned by `vollo_rt_model_input_shape`,
 * it is provided to make it easier to allocate the correct number of elements.
 *
 * Requirements (panics otherwise):
 * - a program was loaded with `vollo_rt_load_program`
 * - `model_index &lt; vollo_rt_num_models`
 * - `input_index &lt; vollo_rt_model_num_inputs`
 */
size_t vollo_rt_model_input_num_elements(
  vollo_rt_context_t vollo, size_t model_index, size_t input_index);

/**
 * Get the number of elements for output at a given index
 *
 * This is simply the product of the dimensions returned by `vollo_rt_model_output_shape`,
 * it is provided to make it easier to allocate the correct number of elements.
 *
 * Requirements (panics otherwise):
 * - a program was loaded with `vollo_rt_load_program`
 * - `model_index &lt; vollo_rt_num_models`
 * - `output_index &lt; vollo_rt_model_num_outputs`
 */
size_t vollo_rt_model_output_num_elements(
  vollo_rt_context_t vollo, size_t model_index, size_t output_index);

/**
 * In a streaming model, the streaming dimension is not part of the shape.
 *
 * - It returns -1 when there is no streaming dimension
 * - It otherwise returns the dim index
 *   For example, for a shape `(a, b, c)` and streaming dim index 1, the full shape is:
 *   `(a, streaming_dim, b, c)`
 *
 * Requirements (panics otherwise):
 * - a program was loaded with `vollo_rt_load_program`
 * - `model_index &lt; vollo_rt_num_models`
 * - `input_index &lt; vollo_rt_model_num_inputs`
 */
int vollo_rt_model_input_streaming_dim(
  vollo_rt_context_t vollo, size_t model_index, size_t input_index);

/**
 * In a streaming model, the streaming dimension is not part of the shape.
 *
 * - It returns -1 when there is no streaming dimension
 * - It otherwise returns the dim index
 *   For example, for a shape `(a, b, c)` and streaming dim index 1, the full shape is:
 *   `(a, streaming_dim, b, c)`
 *
 * Requirements (panics otherwise):
 * - a program was loaded with `vollo_rt_load_program`
 * - `model_index &lt; vollo_rt_num_models`
 * - `output_index &lt; vollo_rt_model_num_outputs`
 */
int vollo_rt_model_output_streaming_dim(
  vollo_rt_context_t vollo, size_t model_index, size_t output_index);
</code></pre>
<h2 id="running-inference"><a class="header" href="#running-inference">Running inference</a></h2>
<p>The interface returns results asynchronously so that inference requests can be made as fast
as the system can support, without blocking on output data being returned. This way, it also
supports running multiple requests concurrently.
Before any compute is started a job with associated input and output buffers needs to be
registered with the runtime using one of <code>vollo_rt_add_job_bf16</code> or <code>vollo_rt_add_job_fp32</code>.</p>
<p>The <code>bf16</code> variant uses <a href="https://cloud.google.com/tpu/docs/bfloat16"><code>bfloat16</code></a>
which is effectively a cropped version of single precision floating point format
<code>fp32</code> (same exponent, smaller mantissa).
Note: do NOT use C floating point literals for <code>bf16</code> as it is simply a <code>uint16_t</code> in the API</p>
<p>A <code>fp32</code> variant is also provided despite the Vollo accelerator expecting its
inputs and outputs to be in <code>fp16</code>. If you are working with <code>fp32</code>, prefer
this version instead of the <code>bf16</code> variant as it is able to make the conversion
while copying to/from DMA buffers, avoiding an extra copy.</p>
<pre><code class="language-c">/**
 * Sets up a computation on the vollo accelerator where the inputs and outputs are in brain-float 16
 * format.
 *
 * Note: The computation is only started on the next call to vollo_rt_poll. This way it is possible
 * to set up several computations that are kicked off at the same time.
 *
 * - vollo:
 *     the context that the computation should be run on
 * - model_index:
 *     the model to run
 * - user_ctx:
 *     a user context that will be returned on completion. This can be used to disambiguate when
 *     multiple models are running concurrently.
 *     NOTE: the jobs for a single model are guaranteed to come back in order, but the jobs for
 *     different models are not.
 * - input_data:
 *     a pointer to the start of an array with pointers to the start of the data to each input the
 *     number of inputs is given by `vollo_rt_model_num_inputs` each input length is the product of
 *     the shape given by `vollo_rt_model_input_shape`
 *     (or more convenient: `vollo_rt_model_input_num_elements`)
 *     lifetime:
 *       - The outer array only needs to live until `vollo_rt_add_job_bf16` returns
 *       - The input buffers need to live until `vollo_rt_poll` returns with the completion for
 *         this job
 * - output_data:
 *     a pointer to the start of an array with pointers to the start of the data to each output
 *     buffer the number of outputs is given by `vollo_rt_model_num_outputs` each output length is
 *     the product of the shape given by `vollo_rt_model_output_shape`
 *     (or more convenient: `vollo_rt_model_output_num_elements`)
 *     lifetime:
 *       - The outer array only needs to live until `vollo_rt_add_job_bf16` returns
 *       - The output buffers need to live until `vollo_rt_poll` returns with the completion for
 *         this job
 */
vollo_rt_error_t vollo_rt_add_job_bf16(
  vollo_rt_context_t vollo,
  size_t model_index,
  uint64_t user_ctx,
  const bf16* const* input_data,
  bf16* const* output_data);

vollo_rt_error_t vollo_rt_add_job_fp32(
  vollo_rt_context_t vollo,
  size_t model_index,
  uint64_t user_ctx,
  const float* const* input_data,
  float* const* output_data);
</code></pre>
<p>To actually start and later complete an inference you must use the <code>vollo_rt_poll</code> function
multiple times. It is typically called in a loop (with a timeout) until some or all of the jobs
are completed.</p>
<pre><code class="language-c">/**
 * Poll the vollo accelerator for completion.
 *
 * Note: Polling also initiates transfers for new jobs, so poll must be called
 * before any progress on these new jobs can be made.
 *
 *   num_completed: out: the number of completed user_ctx returned
 *   returned_user_ctx: buffer for the returned user_ctx of completed jobs, this will only be
 *                      valid until the next call to vollo_rt_poll.
 */
vollo_rt_error_t vollo_rt_poll(
  vollo_rt_context_t vollo, size_t* num_completed, const uint64_t** returned_user_ctx);
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="vollo-rt-example"><a class="header" href="#vollo-rt-example">Vollo RT Example</a></h1>
<p>The full code for this example can be found in <code>example/single-decision.c</code>.</p>
<p>Here we will work through it step by step.</p>
<hr />
<p>First we need to get hold of a Vollo RT context:</p>
<pre><code class="language-c">//////////////////////////////////////////////////
// Init
vollo_rt_context_t ctx;
EXIT_ON_ERROR(vollo_rt_init(&amp;ctx));
</code></pre>
<p>Note: throughout this example we use <code>EXIT_ON_ERROR</code>, it is just a convenient way to handle errors</p>
<hr />
<p>Then we need to add accelerators, the <code>accelerator_index</code> refers to the index of
the Vollo accelerator in the sorted list of PCI addresses, simply use <code>0</code> if you
have a single accelerator, or just want to use the first one.</p>
<pre><code class="language-c">//////////////////////////////////////////////////
// Add accelerators
size_t accelerator_index = 0;
EXIT_ON_ERROR(vollo_rt_add_accelerator(ctx, accelerator_index));
</code></pre>
<p>This step will check the accelerator license and make sure the bitstream is the
correct version and compatible with this version of the runtime.</p>
<hr />
<p>Then we load a program:</p>
<pre><code class="language-c">//////////////////////////////////////////////////
// Load program

// Program for a block_size 64 accelerator
const char* vollo_program_path = "./single-decision-u256.vollo";
EXIT_ON_ERROR(vollo_rt_load_program(ctx, vollo_program_path));
</code></pre>
<p>Here we're using a relative path (in the <code>example</code> directory) to one of the
example Vollo program, a program that computes a simple single decision with an input of size 32.
The program is specifically for a 256-unit version of the accelerator such as the
default configuration for the <code>IA840F</code> FPGA.</p>
<hr />
<p>Then we setup some inputs and outputs for a single inference:</p>
<pre><code class="language-c">//////////////////////////////////////////////////
// Setup inputs and outputs

size_t model_index = 0;

// Assert model only has a single input and a single output tensor
assert(vollo_rt_model_num_inputs(ctx, model_index) == 1);
assert(vollo_rt_model_num_outputs(ctx, model_index) == 1);

assert(vollo_rt_model_input_num_elements(ctx, model_index, 0) == 32);
assert(vollo_rt_model_output_num_elements(ctx, model_index, 0) == 1);

float input_tensor[32];
float output_tensor[1];

for (size_t i = 0; i &lt; 32; i++) {
  input_tensor[i] = 3.0;
}
</code></pre>
<p>We check that the program metadata matches our expectations and we setup an input and output buffer.</p>
<hr />
<p>Then we run a single inference:</p>
<pre><code class="language-c">//////////////////////////////////////////////////
// Run an inference

single_shot_inference(ctx, input_tensor, output_tensor);
</code></pre>
<p>Where we define a convenience function to run this type of simple synchronous
inference on top of the asynchronous Vollo RT API:</p>
<pre><code class="language-c">// A small wrapper around the asynchronous Vollo RT API to block on a single inference
// This assume a single model with a single input and output tensor
static void single_shot_inference(vollo_rt_context_t ctx, const float* input, float* output) {
  size_t model_index = 0;

  const float* inputs[1] = {input};
  float* outputs[1] = {output};

  // user_ctx is not needed when doing single shot inferences
  // it can be used when doing multiple jobs concurrently to keep track of which jobs completed
  uint64_t user_ctx = 0;

  // Register a new job
  EXIT_ON_ERROR(vollo_rt_add_job_fp32(ctx, model_index, user_ctx, inputs, outputs));

  // Poll until completion
  size_t num_completed = 0;
  const uint64_t* completed_buffer = NULL;
  size_t poll_count = 0;

  while (num_completed == 0) {
    EXIT_ON_ERROR(vollo_rt_poll(ctx, &amp;num_completed, &amp;completed_buffer));

    poll_count++;
    if (poll_count &gt; 1000000) {
      EXIT_ON_ERROR("Timed out while polling");
    }
  }
}
</code></pre>
<p>This function does 2 things. First it registers a new job with the Vollo RT
context and then it polls in a loop until that job is complete.</p>
<p>For a more thorough overview of how to use this asynchronous API to run multiple
jobs concurrently take a look at <code>example/example.c</code></p>
<hr />
<p>And finally we print out the newly obtained result and cleanup the Vollo RT context:</p>
<pre><code class="language-c">//////////////////////////////////////////////////
// Print outputs

printf("Output value: [%.1f]\n", output_tensor[0]);

//////////////////////////////////////////////////
// Release resources / Cleanup
vollo_rt_destroy(ctx);
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="vollo-rt-python-example"><a class="header" href="#vollo-rt-python-example">Vollo RT Python Example</a></h1>
<p>The Vollo RT Python bindings are provided for convenience, the runtime
performance of this API is not a priority.</p>
<!-- markdown-link-check-disable -->
<p>Here is a minimal way to use the <a href="./api-reference/vollo_rt.html">Vollo RT Python bindings</a>:</p>
<!-- markdown-link-check-enable -->
<pre><code class="language-python">import vollo_rt
import torch
import os

with vollo_rt.VolloRTContext() as ctx:
    ctx.add_accelerator(0)

    if ctx.accelerator_num_cores(0) == 128:
        ctx.load_program(f"{os.environ["VOLLO_TREES_SDK"]}/example/single-decsision-u128.vollo")
    else:
        ctx.load_program(f"{os.environ["VOLLO_TREES_SDK"]}/example/single-decision-u256.vollo")

    input = torch.rand(*ctx.model_input_shape()).bfloat16()
    output = ctx.run(input)

    torch.testing.assert_close(input, output)
    print("Success!")
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="versions"><a class="header" href="#versions">Versions</a></h1>
<h2 id="version-compatibility"><a class="header" href="#version-compatibility">Version Compatibility</a></h2>
<p>The Vollo Trees SDK follows a semantic versioning scheme.
If the left-most non-zero component (major/minor/patch) of the version number
is unchanged between two releases of the Vollo Trees SDK, it should be possible to
update to the newer version without modifying your existing code, e.g. updating
from 0.1.0 to 0.1.1.</p>
<p>Additionally, the FPGA bitstream is stable between patch releases, so you do
not have to reprogram the FPGA with an updated Vollo Trees bitstream unless the
minor or major version numbers have changed.</p>
<h2 id="documentation-for-previous-versions"><a class="header" href="#documentation-for-previous-versions">Documentation for Previous Versions</a></h2>
<p>Documentation for previous versions of the Vollo Trees SDK can be found in this
listing:</p>
<!-- version-listing-anchor-start -->
<!-- version-listing-anchor-end --><div style="break-before: page; page-break-before: always;"></div><h1 id="release-notes"><a class="header" href="#release-notes">Release Notes</a></h1>
<h2 id="010"><a class="header" href="#010">0.1.0</a></h2>
<ul>
<li>First release of decision tree accelerator</li>
</ul>

                </main>

                <nav class="nav-wrapper" aria-label="Page navigation">
                    <!-- Mobile navigation buttons -->


                    <div style="clear: both"></div>
                </nav>
            </div>
        </div>

        <nav class="nav-wide-wrapper" aria-label="Page navigation">

        </nav>

    </div>




    <script type="text/javascript">
        window.playground_copyable = true;
    </script>


    <script src="elasticlunr.min.js" type="text/javascript" charset="utf-8"></script>
    <script src="mark.min.js" type="text/javascript" charset="utf-8"></script>
    <script src="searcher.js" type="text/javascript" charset="utf-8"></script>

    <script src="clipboard.min.js" type="text/javascript" charset="utf-8"></script>
    <script src="highlight.js" type="text/javascript" charset="utf-8"></script>
    <script src="book.js" type="text/javascript" charset="utf-8"></script>

    <!-- Custom JS scripts -->

    <script type="text/javascript">
        window.addEventListener('load', function () {
            window.setTimeout(window.print, 100);
        });
    </script>

</body>

</html>
